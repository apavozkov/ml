# Отчёт ДЗ1

### Выбор датасета
В работе использован датсет clf_num_bank-marketing из набора inria-soda/tabular-benchmark, размещённого на Hugging Face.

### Формулировка задачи
В работе решается задача бинарной классификации.<br>
Необходимо предсказать значение переменной class, которая показывает, согласится ли клиент банка на миаркетинговое предложение (1 - да, 0 -нет).

### Анализ данных
Датасет содержит числовые признаки, характеризующие клиентов банка.<br>
Размер тестовой выборки после разбиения: 2116 объектов.<br>
Распределение классов в тест выборке:
- Согласны: 1058 об.
- Не согласны: 1058 об.
<br>
Данные сбалансированы. Метрика Accurancy не искажена дисбалансом.<br>
Пропуски обработаны медианной импутацией.<br>
Признаки масштабированы через StandartScaler.<br>

### Обучение модели
Обучены 2 модели:
- Logistic Regression
- Decision Tree

### Результаты моделей
#### Logistic Regression
Accuracy: 0.7443<br>
F1-macro: 0.7439<br>
class1 precision = 0.73<br>
class1 recall = 0.79<br>
class1 f1 = 0.75<br>
class2 precision = 0.77<br>
class2 recall = 0.70<br>
class2 f1 = 0.73<br>
<br>
Анализ:
- Модель лучше распознаёт class1 тк выше recall.
- class2 чаще ошибочно классифицируется как class1.
- Качество по классам более менее сбалансировано.
#### Decision Tree (без ограничений глубины)
Accuracy: 0.7245<br>
F1-macro: 0.7245<br>
class1 precision = 0.72<br>
class1 recall = 0.73<br>
class1 f1 = 0.73<br>
class2 precision = 0.73<br>
class2 recall = 0.72<br>
class2 f1 = 0.72<br>
<br>
Анализ:
- Модель показвает худшие показатели в сравнении с LR.
- Ошибки распределены равномерно.
- Возможно, имеет место переобучение.
#### Decision Tree (max_depth=5)
Accuracy: 0.7802<br>
F1-macro: 0.7802<br>
Это лучший результат среди моделей.
<br>
Анализ:
- Ограничение глубины существенно улучшило качество.
- DT переобучалось, сейчас нет.
### Эксперимент: удаление признака
Удалён признак V1<br>
Результаты LR без V1:
- Accuracy: 0.7405 (было 0.7443)
- F1-macro: 0.7401 (было 0.405)
<br>
Качество снизилось. Соответственно, V1 является информативным признаком.<br>
### Выводы
- Задача бинарной классификация решена.
- Данные сбалансированы по классам.
- LR даёт стабильные и сбалансированные результаты.
- DT без ограничений даёт худшие результаты.
- DT с ограничением max_depth=5 дало лучший резултат (accuracy = 0.78).
- Удаление V1 дало снижение качестива, что подтверждает его значимость.

